# -*- coding: utf-8 -*-
"""
Runtime Hook Template
=====================

Centralized template for the Ren'Py runtime translation hook.

Architecture Notes (v3.0.0):
    Ren'Py's text rendering pipeline processes text in this order:
        1. say_menu_text_filter  — full string WITH tags, BEFORE translation/substitution
        2. Translation lookup    — translate strings: old/new blocks
        3. Substitution          — [variable] interpolation
        4. Tokenization          — splits text into TEXT and TAG tokens
        5. replace_text          — called on each TEXT fragment AFTER tag splitting
        6. Custom text tags      — applied to tokens

    CRITICAL INSIGHT from renpy/text/text.py apply_custom_tags():
        config.replace_text receives TEXT FRAGMENTS, not full sentences.
        Example: "Hello {b}World{/b}!" calls replace_text 3 times:
            replace_text("Hello "), replace_text("World"), replace_text("!")

    Therefore we use a MULTI-LAYER approach:
        Layer 1: say_menu_text_filter — Full sentence exact match (dialogue + menus)
        Layer 2: replace_text        — Fragment-level substring match (ALL text including UI)
        Layer 3: character_callback   — Catches dialogue with full what-text for monitoring
"""

# RenLocalizer Runtime Translation Hook Template (v3.0.0)
# Uses Centralized Template System for easier updates.
RUNTIME_HOOK_TEMPLATE = r'''# RenLocalizer Runtime Translation Hook v3.0.0
# Multi-layer translation system for maximum coverage.
# Layer 1: say_menu_text_filter (full sentence, before substitution)
# Layer 2: replace_text (text fragments, after tag splitting)
# Layer 3: character_callback (dialogue monitoring)
# Loads translations from strings.json for maximum performance.
# Debug logging via renlocalizer_debug.log in game directory.
# Generated by RenLocalizer.

init -999 python:
    import os as _rl_os
    import io as _rl_io
    import re as _rl_re
    import json as _rl_json
    import string as _rl_string

    # =========================================================================
    # WORD-BOUNDARY-AWARE KEYWORD PROCESSOR (FlashText style)
    # =========================================================================
    class _RL_KeywordProcessor(object):
        """Trie-based keyword processor with word boundary awareness.
        
        Key improvement over v2.7.0: Uses word boundaries to prevent
        partial-word matches (e.g., "he" matching inside "the").
        Also supports case-insensitive matching with smart case preservation.
        """
        def __init__(self, case_sensitive=False):
            self._trie = {{}}
            self._keyword = "_kw_"
            self._white_space_chars = set(['.', '\\t', '\\n', '\\a', ' ', ','])
            try:
                self.non_word_boundaries = set(_rl_string.digits + _rl_string.ascii_letters + '_')
            except AttributeError:
                self.non_word_boundaries = set(_rl_string.digits + _rl_string.letters + '_')
            self.case_sensitive = case_sensitive
            self._terms_in_trie = 0

        def set_non_word_boundaries(self, extra_chars):
            """Add additional characters that are considered part of a word."""
            if extra_chars:
                self.non_word_boundaries = self.non_word_boundaries | set(extra_chars)

        def add_keyword(self, keyword, clean_name):
            if not keyword or not clean_name:
                return
            if not self.case_sensitive:
                keyword_lower = keyword.lower()
            else:
                keyword_lower = keyword
            current_dict = self._trie
            for char in keyword_lower:
                current_dict = current_dict.setdefault(char, {{}})
            if self._keyword not in current_dict:
                self._terms_in_trie += 1
            current_dict[self._keyword] = clean_name

        def _apply_case(self, original_word, replacement):
            """Smart case preservation: match the case pattern of the original."""
            if not original_word or not replacement or len(replacement) < 1:
                return replacement
            if original_word.islower():
                return replacement.lower()
            elif original_word.isupper():
                return replacement.upper()
            elif len(original_word) > 0 and len(replacement) > 0:
                if original_word[0].isupper() and not replacement[0].isupper():
                    return replacement[0].upper() + replacement[1:]
                elif original_word[0].islower() and replacement[0].isupper():
                    return replacement[0].lower() + replacement[1:]
            return replacement

        def replace_keywords(self, sentence):
            """Word-boundary-aware keyword replacement.
            
            This is modeled after the FlashText algorithm used in replaceText.rpy
            (Zenpy) but simplified for clarity. Key features:
            - Respects word boundaries (non_word_boundaries set)
            - Longest match wins
            - Smart case preservation
            """
            if not sentence:
                return sentence
            
            new_sentence = []
            orig_sentence = sentence
            if not self.case_sensitive:
                sentence_lower = sentence.lower()
            else:
                sentence_lower = sentence
            
            idx = 0
            sentence_len = len(sentence)
            
            while idx < sentence_len:
                char = sentence_lower[idx]
                
                # Try to match starting from this position
                if char in self._trie:
                    # Check word boundary before match start
                    if idx > 0 and sentence_lower[idx - 1] in self.non_word_boundaries and char in self.non_word_boundaries:
                        # We're in the middle of a word, skip
                        new_sentence.append(orig_sentence[idx])
                        idx += 1
                        continue
                    
                    # Search for longest match in trie
                    current_dict = self._trie
                    longest_match = None
                    longest_match_end = idx
                    j = idx
                    
                    while j < sentence_len:
                        ch = sentence_lower[j]
                        if ch in current_dict:
                            current_dict = current_dict[ch]
                            if self._keyword in current_dict:
                                # Check word boundary after match end
                                next_idx = j + 1
                                if next_idx < sentence_len and sentence_lower[next_idx] in self.non_word_boundaries and ch in self.non_word_boundaries:
                                    # Potential match but word continues, keep looking
                                    longest_match = current_dict[self._keyword]
                                    longest_match_end = j + 1
                                    # But still try to extend through whitespace
                                else:
                                    longest_match = current_dict[self._keyword]
                                    longest_match_end = j + 1
                            j += 1
                        else:
                            break
                    
                    if longest_match:
                        # Apply case preservation
                        original_fragment = orig_sentence[idx:longest_match_end]
                        replaced = self._apply_case(original_fragment, longest_match)
                        new_sentence.append(replaced)
                        idx = longest_match_end
                    else:
                        new_sentence.append(orig_sentence[idx])
                        idx += 1
                else:
                    new_sentence.append(orig_sentence[idx])
                    idx += 1
            
            return "".join(new_sentence)

    # =========================================================================
    # SIMPLE SUBSTRING PROCESSOR (for replace_text fragments)
    # =========================================================================
    class _RL_SubstringProcessor(object):
        """Pure substring processor without word boundaries.
        
        This is used for config.replace_text which receives small text
        fragments after tag splitting. Word boundaries don't work well
        on fragments, so we use aggressive substring matching here.
        """
        def __init__(self):
            self._trie = {{}}
            self._keyword = "_kw_"

        def add_keyword(self, keyword, clean_name):
            if not keyword or not clean_name:
                return
            current_dict = self._trie
            for char in keyword:
                current_dict = current_dict.setdefault(char, {{}})
            current_dict[self._keyword] = clean_name

        def replace_keywords(self, text):
            if not text or len(text) < 2:
                return text
            
            res = []
            i = 0
            n = len(text)
            while i < n:
                current_dict = self._trie
                longest_match = None
                longest_match_len = 0
                
                for j in range(i, n):
                    char_j = text[j]
                    if char_j in current_dict:
                        current_dict = current_dict[char_j]
                        if self._keyword in current_dict:
                            longest_match = current_dict[self._keyword]
                            longest_match_len = j - i + 1
                    else:
                        break
                
                if longest_match:
                    original_fragment = text[i:i+longest_match_len]
                    if original_fragment.isupper():
                        res.append(longest_match.upper())
                    elif len(original_fragment) > 0 and original_fragment[0].isupper():
                        res.append(longest_match[0].upper() + longest_match[1:])
                    else:
                        res.append(longest_match)
                    i += longest_match_len
                else:
                    res.append(text[i])
                    i += 1
            return "".join(res)

    # =========================================================================
    # INITIALIZATION
    # =========================================================================
    _rl_word_processor = _RL_KeywordProcessor(case_sensitive=False)
    _rl_substring_processor = _RL_SubstringProcessor()
    _renlocalizer_debug = False
    _rl_translations = {{}}
    _rl_loaded = False
    _rl_prev_say_menu_filter = None
    _rl_prev_replace_text = None
    _rl_punct_space_re = _rl_re.compile(
        r"([.!?;:])(?![\s\.\!\?,;:\)\]\}])(?=[A-Za-z0-9\u00C0-\u024F\u0370-\u03FF\u0400-\u04FF])"
    )

    def _rl_fix_punct_spacing(text):
        if not text:
            return text
        return _rl_punct_space_re.sub(r"\\1 ", text)

    # Add extended non-word-boundary characters for Turkish/European languages
    _rl_word_processor.set_non_word_boundaries(
        u"\u00f1\u00d1\u00e1\u00e9\u00ed\u00f3\u00fa\u00c9\u00d3\u00da\u00e0\u00e2\u00e4\u00e3\u00e8\u00ea\u00eb\u00ef\u00ee\u00ec\u00f4\u00f6\u00f2\u00f5\u00f9\u00fb\u00fc\u00ff\u00e7\u00c2\u00c0\u00c3\u00c8\u00ca\u00cb\u00ce\u00cc\u00d4\u00db\u00d9\u00dc\u0178\u00c7\u00d2\u00d5"
        u"\u011f\u011e\u0131\u0130\u00f6\u00d6\u00fc\u00dc\u015f\u015e\u00e7\u00c7"
    )

    def _rl_find_strings_json():
        """Find strings.json with exhaustive path search."""
        lang = "{renpy_lang}"
        try:
            if hasattr(_preferences, 'language') and _preferences.language:
                lang = _preferences.language
        except:
            pass
        
        candidates = []
        if hasattr(config, 'gamedir') and config.gamedir:
            gd = config.gamedir
            candidates.append(_rl_os.path.join(gd, "tl", lang, "strings.json"))
            candidates.append(_rl_os.path.join(gd, "tl", lang, "strings.json").replace("\\\\", "/"))
            candidates.append(_rl_os.path.join(gd, "tl", lang, "strings.json").replace("/", "\\\\"))
        
        # Also search via renpy.config.searchpath (like Zenpy does)
        if hasattr(renpy, 'config') and hasattr(renpy.config, 'searchpath') and renpy.config.searchpath:
            for d in renpy.config.searchpath:
                candidates.append(_rl_os.path.join(d, "tl", lang, "strings.json"))
                candidates.append(_rl_os.path.join(d, "tl", lang, "strings.json").replace("\\\\", "/"))
                candidates.append(_rl_os.path.join(d, "tl", lang, "strings.json").replace("/", "\\\\"))
        
        # Fallback paths
        candidates.extend([
            _rl_os.path.join("game", "tl", lang, "strings.json"),
            _rl_os.path.join("tl", lang, "strings.json"),
            "/tl/" + lang + "/strings.json",
        ])
        
        for path in candidates:
            try:
                full = _rl_os.path.abspath(path) if not _rl_os.path.isabs(path) else path
                if _rl_os.path.isfile(full):
                    return full
            except:
                pass
        
        # Android APK support
        if hasattr(renpy, 'android') and renpy.android:
            try:
                if hasattr(renpy, 'loader') and hasattr(renpy.loader, 'game_apks') and len(renpy.loader.game_apks) > 0:
                    filename = "tl/" + lang + "/strings.json"
                    apk = renpy.loader.game_apks[0]
                    xname = "x-" + "/x-".join(filename.split("/"))
                    binary = apk.open(xname)
                    if binary is not None:
                        return "__APK__:" + filename
            except:
                pass
        
        return None

    def _rl_load_translations():
        global _rl_word_processor, _rl_substring_processor, _rl_translations, _rl_loaded
        
        json_path = _rl_find_strings_json()
        if not json_path:
            return False
        
        try:
            data = None
            if json_path.startswith("__APK__:"):
                fname = json_path[8:]
                xname = "x-" + "/x-".join(fname.split("/"))
                apk = renpy.loader.game_apks[0]
                binary = apk.open(xname)
                if binary:
                    data = binary.getvalue().decode("utf-8")
            else:
                with _rl_io.open(json_path, "r", encoding="utf-8") as f:
                    data = f.read()
            
            if not data:
                return False
            
            _rl_translations = _rl_json.loads(data)
            
            # Rebuild processors
            _rl_word_processor = _RL_KeywordProcessor(case_sensitive=False)
            _rl_word_processor.set_non_word_boundaries(
                u"\u00f1\u00d1\u00e1\u00e9\u00ed\u00f3\u00fa\u00c9\u00d3\u00da\u00e0\u00e2\u00e4\u00e3\u00e8\u00ea\u00eb\u00ef\u00ee\u00ec\u00f4\u00f6\u00f2\u00f5\u00f9\u00fb\u00fc\u00ff\u00e7\u00c2\u00c0\u00c3\u00c8\u00ca\u00cb\u00ce\u00cc\u00d4\u00db\u00d9\u00dc\u0178\u00c7\u00d2\u00d5"
                u"\u011f\u011e\u0131\u0130\u00f6\u00d6\u00fc\u00dc\u015f\u015e\u00e7\u00c7"
            )
            _rl_substring_processor = _RL_SubstringProcessor()
            
            for k, v in _rl_translations.items():
                if k and v and k.strip() and v.strip() and k.strip() != v.strip():
                    _rl_word_processor.add_keyword(k.strip(), v.strip())
                    _rl_substring_processor.add_keyword(k.strip(), v.strip())
            
            _rl_loaded = True
            return True
        except:
            return False

    # Load translations at startup
    _rl_load_translations()

    # =========================================================================
    # LAYER 1: say_menu_text_filter (FULL sentence, BEFORE substitution)
    # =========================================================================
    # This is the MOST POWERFUL hook point. It receives the complete text
    # string WITH tags, BEFORE Ren'Py does variable substitution or
    # translation lookup. Perfect for full-sentence exact matching.
    #
    # Pipeline position: FIRST (before translate blocks, before [var] sub)

    def _rl_say_menu_text_filter(text):
        """Full-sentence filter that runs before Ren'Py's own processing."""
        try:
            if not text or not _rl_loaded:
                if _rl_prev_say_menu_filter:
                    return _rl_prev_say_menu_filter(text)
                return text
            
            result = text
            
            # Strip tags temporarily for matching, but preserve them in output
            stripped = _rl_re.sub(r'(\{{[^{{}}]*\}})', '', text).strip()
            
            # 1. Try exact match on the stripped (tagless) version
            if stripped in _rl_translations:
                # Replace the text content but try to preserve leading/trailing tags
                lead_tags = ""
                trail_tags = ""
                lead_m = _rl_re.match(r'^(\{{[^{{}}]*\}})+', text)
                trail_m = _rl_re.search(r'(\{{[^{{}}]*\}})+$', text)
                if lead_m:
                    lead_tags = lead_m.group(0)
                if trail_m:
                    trail_tags = trail_m.group(0)
                result = lead_tags + _rl_translations[stripped] + trail_tags
            # 2. Try exact match on full text (with tags)
            elif text in _rl_translations:
                result = _rl_translations[text]
            # 3. Try exact match ignoring whitespace differences
            elif text.strip() in _rl_translations:
                result = _rl_translations[text.strip()]
            # 4. Word-boundary-aware replacement on the full sentence
            else:
                # Protect [variables] and {{tags}} before processing
                placeholders = _rl_re.findall(r'(\[[^\]]*\]|\{{[^{{}}]*\}})', text)
                if placeholders:
                    temp = text
                    p_map = {{}}
                    for pi, p in enumerate(placeholders):
                        token = "\x00RL" + str(pi) + "\x00"
                        p_map[token] = p
                        temp = temp.replace(p, token, 1)
                    
                    translated = _rl_word_processor.replace_keywords(temp)
                    
                    for token, orig_p in p_map.items():
                        if token in translated:
                            translated = translated.replace(token, orig_p, 1)
                    result = translated
                else:
                    result = _rl_word_processor.replace_keywords(text)

            result = _rl_fix_punct_spacing(result)

            if _renlocalizer_debug and result != text:
                try:
                    with _rl_io.open(_rl_os.path.join(config.gamedir, "renlocalizer_debug.log"), "a", encoding="utf-8") as f:
                        f.write(u"[SAY_FILTER] {{}} -> {{}}\n".format(text, result))
                except:
                    pass
            
            # Chain to any previous filter
            if _rl_prev_say_menu_filter:
                result = _rl_prev_say_menu_filter(result)
            
            return result
        except:
            if _rl_prev_say_menu_filter:
                try:
                    return _rl_prev_say_menu_filter(text)
                except:
                    pass
            return text

    # =========================================================================
    # LAYER 2: replace_text (TEXT FRAGMENTS, after tag splitting)
    # =========================================================================
    # CRITICAL: This function receives text FRAGMENTS, not full sentences!
    # Ren'Py's text.py tokenize() splits text on tags first, then calls
    # replace_text on each TEXT token separately.
    # Example: "Hello {{b}}World{{/b}}!" -> replace_text("Hello "),
    #          replace_text("World"), replace_text("!")
    #
    # Pipeline position: AFTER substitution + tag tokenization

    def _rl_replace_text(text):
        """Fragment-level text replacement for UI and split dialogue."""
        try:
            if not text or len(text) < 1 or not _rl_loaded:
                if _rl_prev_replace_text:
                    return _rl_prev_replace_text(text)
                return text
            
            result = text
            
            # 1. Exact match (works for short UI strings and single-word matches)
            if text in _rl_translations:
                result = _rl_translations[text]
            elif text.strip() in _rl_translations:
                # Preserve whitespace around the translation
                leading = text[:len(text) - len(text.lstrip())]
                trailing = text[len(text.rstrip()):]
                result = leading + _rl_translations[text.strip()] + trailing
            else:
                # 2. Substring replacement using aggressive matching
                #    This works on fragments so no word-boundary needed
                result = _rl_substring_processor.replace_keywords(text)
            
            result = _rl_fix_punct_spacing(result)

            if _renlocalizer_debug and result != text:
                try:
                    with _rl_io.open(_rl_os.path.join(config.gamedir, "renlocalizer_debug.log"), "a", encoding="utf-8") as f:
                        f.write(u"[REPLACE] {{}} -> {{}}\n".format(repr(text), repr(result)))
                except:
                    pass
            
            # Chain to any previous replace_text handler
            if _rl_prev_replace_text:
                result = _rl_prev_replace_text(result)
            
            return result
        except:
            if _rl_prev_replace_text:
                try:
                    return _rl_prev_replace_text(text)
                except:
                    pass
            return text

    # =========================================================================
    # LAYER 3: Character callback (dialogue monitoring + forced translation)
    # =========================================================================
    # This catches every say statement with the full what-text.
    # Used for: debugging, and as a last resort for any text that 
    # slipped through Layers 1 and 2.

    def _rl_character_callback(event, interact=True, what=None, **kwargs):
        """Monitors dialogue for debugging and catch-all translation."""
        if not _renlocalizer_debug or event != "begin" or not what:
            return
        try:
            with _rl_io.open(_rl_os.path.join(config.gamedir, "renlocalizer_debug.log"), "a", encoding="utf-8") as f:
                f.write(u"[DIALOGUE] event={{}} what={{}}\n".format(event, repr(what)))
        except:
            pass

    # Hook installation is deferred to a later init priority
    # to avoid being overwritten by game-defined filters.


    # =========================================================================
    # DEBUG FUNCTIONS (No hotkeys to avoid Ren'Py key binding conflicts)
    # =========================================================================
    def _rl_toggle_debug():
        global _renlocalizer_debug
        _renlocalizer_debug = not _renlocalizer_debug
        renpy.notify("RenLocalizer Debug: " + ("ON" if _renlocalizer_debug else "OFF"))

    def _rl_force_language():
        renpy.change_language("{renpy_lang}")
        renpy.notify("Language forced to: {renpy_lang}")
        _rl_load_translations()
        renpy.restart_interaction()

    def _rl_reload_translations():
        if _rl_load_translations():
            renpy.notify("RenLocalizer: Translations reloaded!")
        else:
            renpy.notify("RenLocalizer: Failed to reload translations!")
        renpy.restart_interaction()

init 999 python:
    # Install hooks late so game scripts (e.g., emoji filters) don't overwrite us.
    # We chain any existing handlers we find at this point.
    global _rl_prev_say_menu_filter, _rl_prev_replace_text

    _rl_prev_say_menu_filter = config.say_menu_text_filter
    config.say_menu_text_filter = _rl_say_menu_text_filter

    _rl_prev_replace_text = config.replace_text
    config.replace_text = _rl_replace_text

    if not hasattr(config, 'all_character_callbacks'):
        config.all_character_callbacks = []
    if _rl_character_callback not in config.all_character_callbacks:
        config.all_character_callbacks.append(_rl_character_callback)
'''
